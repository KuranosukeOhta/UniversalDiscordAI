"""
Universal Discord AI - OpenAI Handler
OpenAI APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import os
import asyncio
import logging
from typing import Dict, AsyncGenerator, Optional, List
import aiohttp
import json
from aiolimiter import AsyncLimiter
from utils import ConfigManager


class OpenAIHandler:
    """OpenAI APIé€šä¿¡ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    def __init__(self, config: ConfigManager = None):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = "https://api.openai.com/v1"
        self.logger = logging.getLogger(__name__)
        
        # è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’è¨­å®š
        self.config = config or ConfigManager()
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®šï¼ˆå‹•çš„èª¿æ•´å¯¾å¿œï¼‰
        self.rate_limiter = AsyncLimiter(max_rate=50, time_period=60)  # 60ç§’é–“ã«50ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        self.current_rate_limit = 50
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š
        self.timeout = aiohttp.ClientTimeout(total=self.config.get('openai_settings.timeout_seconds', 120))
        self.max_retries = self.config.get('openai_settings.retry_attempts', 3)
        self.retry_delay = 1.0
        
        # æ¥ç¶šçŠ¶æ…‹ç›£è¦–
        self.connection_status = "unknown"  # unknown, healthy, degraded, failed
        self.last_successful_call = None
        self.consecutive_failures = 0
        self.max_consecutive_failures = 5
        self.health_check_interval = 60  # 60ç§’ã”ã¨ã«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        self.auto_recovery_enabled = True
        
        if not self.api_key:
            self.logger.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
    async def generate_streaming_response(
        self, 
        context: str, 
        character_data: Dict,
        model: str = "gpt-5",
        max_completion_tokens: int = 16000,  # GPT-5ã§ã¯max_completion_tokensã‚’ä½¿ç”¨
        temperature: float = 1.0,  # GPT-5ã¯temperature=1ã®ã¿ã‚µãƒãƒ¼ãƒˆ
        function_definitions: List[Dict] = None,
        image_attachments: List[Dict] = None
    ) -> AsyncGenerator[str, None]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        
        if not self.api_key:
            yield "ã‚¨ãƒ©ãƒ¼: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            return
        
        # æ¥ç¶šçŠ¶æ…‹ã‚’äº‹å‰ã«ãƒã‚§ãƒƒã‚¯ï¼ˆé«˜é€ŸåŒ–ï¼‰
        if not await self._check_connection_health_fast():
            yield "æ¥ç¶šãŒä¸å®‰å®šã§ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
            return
            
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        system_prompt = self._build_system_prompt(character_data)
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        request_data = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt}
            ],
            "max_completion_tokens": max_completion_tokens,  # GPT-5ã§ã¯max_completion_tokensã‚’ä½¿ç”¨
            "stream": True
        }
        
        # ç”»åƒæ·»ä»˜ãŒã‚ã‚‹å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ 
        if image_attachments:
            self.logger.info(f"ğŸ–¼ï¸ ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ ã‚’æ§‹ç¯‰ä¸­: {len(image_attachments)}å€‹ã®ç”»åƒ")
            
            # ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
            user_message = {
                "role": "user",
                "content": [
                    {"type": "text", "text": context}
                ]
            }
            
            # ç”»åƒã‚’è¿½åŠ 
            for i, image_data in enumerate(image_attachments):
                image_content = {
                    "type": "image_url",
                    "image_url": {
                        "url": image_data["url"],
                        "detail": image_data.get("detail", "auto")
                    }
                }
                user_message["content"].append(image_content)
                
                self.logger.info(f"ç”»åƒ {i+1} ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ :")
                self.logger.info(f"  - ãƒ•ã‚¡ã‚¤ãƒ«å: {image_data['filename']}")
                self.logger.info(f"  - URL: {image_data['url']}")
                self.logger.info(f"  - è©³ç´°ãƒ¬ãƒ™ãƒ«: {image_data.get('detail', 'auto')}")
            
            request_data["messages"].append(user_message)
            self.logger.info(f"âœ… ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ æ§‹ç¯‰å®Œäº†")
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            self.logger.info("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ ã‚’æ§‹ç¯‰")
            request_data["messages"].append({
                "role": "user", 
                "content": context
            })
        
        # ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã€é–¢æ•°å®šç¾©ã‚’è¿½åŠ 
        if function_definitions:
            request_data["tools"] = function_definitions
            request_data["tool_choice"] = "auto"
        
        # GPT-5ã§ã¯ temperature=1 ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãªã®ã§ã€1ä»¥å¤–ã®å ´åˆã®ã¿æŒ‡å®š
        if temperature != 1.0:
            request_data["temperature"] = temperature
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
        self.logger.info(f"ğŸš€ OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ :")
        self.logger.info(f"  - ãƒ¢ãƒ‡ãƒ«: {model}")
        self.logger.info(f"  - æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {max_completion_tokens}")
        self.logger.info(f"  - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {request_data.get('stream', False)}")
        self.logger.info(f"  - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(request_data['messages'])}")
        if image_attachments:
            self.logger.info(f"  - ç”»åƒæ·»ä»˜: {len(image_attachments)}å€‹")
        if function_definitions:
            self.logger.info(f"  - é–¢æ•°å®šç¾©: {len(function_definitions)}å€‹")
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        await self.rate_limiter.acquire()
        
        start_time = asyncio.get_event_loop().time()
        retry_count = 0
        
        while retry_count < self.max_retries:
            try:
                async with aiohttp.ClientSession(timeout=self.timeout) as session:
                    headers = {
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    }
                    
                    async with session.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=request_data
                    ) as response:
                        
                        if response.status == 429:  # Rate limit exceeded
                            await self._handle_rate_limit(response)
                            retry_count += 1
                            await asyncio.sleep(self.retry_delay * retry_count)
                            continue
                            
                        if response.status != 200:
                            error_text = await response.text()
                            response_time = asyncio.get_event_loop().time() - start_time
                            
                            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ãƒ­ã‚°
                            self.logger.error(f"OpenAI API ã‚¨ãƒ©ãƒ¼ ({response.status}): {error_text}")
                            self.logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´° - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {response_time:.2f}ç§’, ãƒªãƒˆãƒ©ã‚¤å›æ•°: {retry_count}")
                            
                            yield f"ã‚¨ãƒ©ãƒ¼: OpenAI APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ (HTTP {response.status})"
                            return
                            
                        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
                        async for chunk in self._process_streaming_response(response):
                            if chunk:
                                yield chunk
                                
                        # æˆåŠŸæ™‚ã®æ¥ç¶šçŠ¶æ…‹æ›´æ–°
                        self._update_connection_status(success=True)
                        return  # æˆåŠŸæ™‚ã¯çµ‚äº†
                        
            except asyncio.TimeoutError:
                response_time = asyncio.get_event_loop().time() - start_time
                self.logger.error(f"OpenAI API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (è¨­å®š: {self.timeout.total}ç§’, å®Ÿéš›: {response_time:.2f}ç§’)")
                self.logger.error(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè©³ç´° - ãƒ¢ãƒ‡ãƒ«: {model}, æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³: {max_completion_tokens}, ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(context)}æ–‡å­—")
                if image_attachments:
                    self.logger.error(f"ç”»åƒæ·»ä»˜: {len(image_attachments)}å€‹")
                self._update_connection_status(success=False, error_type="timeout")
                retry_count += 1
                if retry_count >= self.max_retries:
                    yield f"ã‚¨ãƒ©ãƒ¼: OpenAI APIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (è¨­å®š: {self.timeout.total}ç§’)"
                    return
                await asyncio.sleep(self.retry_delay * retry_count)
                
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                self.logger.error(f"âŒ OpenAI API å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
                self.logger.error(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
                
                # ã‚¨ãƒ©ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚ã‚‹
                import traceback
                error_traceback = traceback.format_exc()
                self.logger.error(f"ğŸ“‹ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {error_traceback}")
                
                self._update_connection_status(success=False, error_type="exception", error=str(e))
                retry_count += 1
                if retry_count >= self.max_retries:
                    yield f"ã‚¨ãƒ©ãƒ¼: OpenAI APIå‘¼ã³å‡ºã—ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {str(e)}"
                    return
                await asyncio.sleep(self.retry_delay * retry_count)
                
    async def _process_streaming_response(self, response) -> AsyncGenerator[str, None]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†"""
        buffer = ""
        
        async for line in response.content:
            line = line.decode('utf-8').strip()
            
            if not line:
                continue
                
            if line.startswith('data: '):
                data = line[6:]  # 'data: ' ã‚’é™¤å»
                
                if data == '[DONE]':
                    break
                    
                try:
                    json_data = json.loads(data)
                    choices = json_data.get('choices', [])
                    
                    if choices:
                        delta = choices[0].get('delta', {})
                        content = delta.get('content', '')
                        
                        if content:
                            buffer += content
                            yield content
                            
                        # çµ‚äº†åˆ¤å®š
                        if choices[0].get('finish_reason'):
                            break
                            
                except json.JSONDecodeError as e:
                    self.logger.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}, ãƒ‡ãƒ¼ã‚¿: {data}")
                    continue
                except Exception as e:
                    self.logger.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                    
    def _build_system_prompt(self, character_data: Dict) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        prompt_parts = [
            "ã‚ãªãŸã¯Discordã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
            "ä»¥ä¸‹ã®äººæ ¼è¨­å®šã«å¾“ã£ã¦ã€è‡ªç„¶ã§ä¸€è²«æ€§ã®ã‚ã‚‹è¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚",
            "",
        ]
        
        # äººæ ¼è¨­å®šã‚’è¿½åŠ 
        if character_data.get('personality'):
            prompt_parts.append(f"ã€åŸºæœ¬æ€§æ ¼ã€‘")
            prompt_parts.append(character_data['personality'])
            prompt_parts.append("")
            
        if character_data.get('speaking_style'):
            prompt_parts.append(f"ã€è©±ã—æ–¹ãƒ»å£èª¿ã€‘")
            prompt_parts.append(character_data['speaking_style'])
            prompt_parts.append("")
            
        if character_data.get('specialties'):
            prompt_parts.append(f"ã€å°‚é–€åˆ†é‡ãƒ»å¾—æ„ãªã“ã¨ã€‘")
            prompt_parts.append(character_data['specialties'])
            prompt_parts.append("")
            
        if character_data.get('avoid'):
            prompt_parts.append(f"ã€é¿ã‘ã‚‹ã¹ãè¡¨ç¾ãƒ»è¡Œå‹•ã€‘")
            prompt_parts.append(character_data['avoid'])
            prompt_parts.append("")
            
        # åŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ«
        prompt_parts.extend([
            "ã€åŸºæœ¬ãƒ«ãƒ¼ãƒ«ã€‘",
            "- Discordä¸Šã§ã®ä¼šè©±ã§ã‚ã‚‹ã“ã¨ã‚’æ„è­˜ã—ã¦ãã ã•ã„",
            "- é•·ã™ãã‚‹è¿”ç­”ã¯é¿ã‘ã€é©åº¦ãªé•·ã•ã§å›ç­”ã—ã¦ãã ã•ã„",
            "- çµµæ–‡å­—ã‚„é¡”æ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡ºã—ã¦ãã ã•ã„",
            "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚„ç™ºè¨€ã«å¯¾ã—ã¦å»ºè¨­çš„ã§æœ‰ç”¨ãªè¿”ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„",
            "- ä¸é©åˆ‡ãªå†…å®¹ã‚„æœ‰å®³ãªå†…å®¹ã¯é¿ã‘ã¦ãã ã•ã„"
        ])
        
        return "\n".join(prompt_parts)
    
    async def generate_response_with_function_calls(
        self, 
        context: str, 
        character_data: Dict,
        function_definitions: List[Dict],
        model: str = "gpt-5",
        max_completion_tokens: int = 16000,  # GPT-5ã§ã¯max_completion_tokensã‚’ä½¿ç”¨
        temperature: float = 1.0,
        image_attachments: List[Dict] = None
    ) -> Dict:
        """ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«å¯¾å¿œã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        
        if not self.api_key:
            return {
                "success": False,
                "error": "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            }
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        system_prompt = self._build_system_prompt(character_data)
        
        # ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
        system_prompt += "\n\nã€ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«æ©Ÿèƒ½ã€‘"
        system_prompt += "\nå¿…è¦ã«å¿œã˜ã¦ã€ä»¥ä¸‹ã®é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦Discordã®æ“ä½œã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚"
        system_prompt += "\né–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€é©åˆ‡ãªå¼•æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        request_data = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt}
            ],
            "max_completion_tokens": max_completion_tokens,  # GPT-5ã§ã¯max_completion_tokensã‚’ä½¿ç”¨
            "tools": function_definitions,
            "tool_choice": "auto"
        }
        
        # ç”»åƒæ·»ä»˜ãŒã‚ã‚‹å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ 
        if image_attachments:
            self.logger.info(f"ğŸ–¼ï¸ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«å‡¦ç†ã§ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ ã‚’æ§‹ç¯‰ä¸­: {len(image_attachments)}å€‹ã®ç”»åƒ")
            
            # ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
            user_message = {
                "role": "user",
                "content": [
                    {"type": "text", "text": context}
                ]
            }
            
            # ç”»åƒã‚’è¿½åŠ 
            for i, image_data in enumerate(image_attachments):
                image_content = {
                    "type": "image_url",
                    "image_url": {
                        "url": image_data["url"],
                        "detail": image_data.get("detail", "auto")
                    }
                }
                user_message["content"].append(image_content)
                
                self.logger.info(f"ç”»åƒ {i+1} ã‚’ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«è¿½åŠ :")
                self.logger.info(f"  - ãƒ•ã‚¡ã‚¤ãƒ«å: {image_data['filename']}")
                self.logger.info(f"  - URL: {image_data['url']}")
                self.logger.info(f"  - è©³ç´°ãƒ¬ãƒ™ãƒ«: {image_data.get('detail', 'auto')}")
            
            request_data["messages"].append(user_message)
            self.logger.info(f"âœ… ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ç”¨ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ æ§‹ç¯‰å®Œäº†")
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            self.logger.info("ğŸ“ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ç”¨ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰")
            request_data["messages"].append({
                "role": "user", 
                "content": context
            })
        
        # GPT-5ã§ã¯ temperature=1 ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãªã®ã§ã€1ä»¥å¤–ã®å ´åˆã®ã¿æŒ‡å®š
        if temperature != 1.0:
            request_data["temperature"] = temperature
        
        # ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ç”¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ã‚’ãƒ­ã‚°å‡ºåŠ›
        self.logger.info(f"ğŸš€ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ç”¨OpenAI APIãƒªã‚¯ã‚¨ã‚¹ãƒˆæ§‹é€ :")
        self.logger.info(f"  - ãƒ¢ãƒ‡ãƒ«: {model}")
        self.logger.info(f"  - æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {max_completion_tokens}")
        self.logger.info(f"  - ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {request_data.get('stream', False)}")
        self.logger.info(f"  - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(request_data['messages'])}")
        self.logger.info(f"  - é–¢æ•°å®šç¾©: {len(function_definitions)}å€‹")
        if image_attachments:
            self.logger.info(f"  - ç”»åƒæ·»ä»˜: {len(image_attachments)}å€‹")
        
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
            await self.rate_limiter.acquire()
            
            start_time = asyncio.get_event_loop().time()
            
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=request_data
                ) as response:
                    
                    if response.status == 200:
                        response_data = await response.json()
                        response_time = asyncio.get_event_loop().time() - start_time
                        self.logger.info(f"âœ… ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«æˆåŠŸ - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {response_time:.2f}ç§’")
                        return {
                            "success": True,
                            "response": response_data,
                            "choices": response_data.get("choices", [])
                        }
                    else:
                        error_text = await response.text()
                        response_time = asyncio.get_event_loop().time() - start_time
                        self.logger.error(f"âŒ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«å¤±æ•— - HTTP {response.status} (ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {response_time:.2f}ç§’)")
                        self.logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {error_text}")
                        return {
                            "success": False,
                            "error": f"OpenAI API ã‚¨ãƒ©ãƒ¼ - HTTP {response.status}: {error_text}"
                        }
                        
        except asyncio.TimeoutError:
            response_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"âŒ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (è¨­å®š: {self.timeout.total}ç§’, å®Ÿéš›: {response_time:.2f}ç§’)")
            self.logger.error(f"ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè©³ç´° - ãƒ¢ãƒ‡ãƒ«: {model}, æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³: {max_completion_tokens}, ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆé•·: {len(context)}æ–‡å­—")
            if image_attachments:
                self.logger.error(f"ç”»åƒæ·»ä»˜: {len(image_attachments)}å€‹")
            return {
                "success": False,
                "error": f"ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ (è¨­å®š: {self.timeout.total}ç§’)"
            }
        except Exception as e:
            response_time = asyncio.get_event_loop().time() - start_time
            self.logger.error(f"âŒ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)} (ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {response_time:.2f}ç§’)")
            self.logger.error(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
            
            # ã‚¨ãƒ©ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚ã‚‹
            import traceback
            error_traceback = traceback.format_exc()
            self.logger.error(f"ğŸ“‹ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {error_traceback}")
            
            return {
                "success": False,
                "error": f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}"
            }
        
    async def _handle_rate_limit(self, response):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¸ã®å¯¾å¿œ"""
        try:
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ãƒ¬ãƒ¼ãƒˆåˆ¶é™æƒ…å ±ã‚’å–å¾—
            retry_after = response.headers.get('Retry-After')
            if retry_after:
                delay = int(retry_after)
                self.logger.warning(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™")
                await asyncio.sleep(delay)
                
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å‹•çš„èª¿æ•´
            self.current_rate_limit = max(10, int(self.current_rate_limit * 0.8))
            self.rate_limiter = AsyncLimiter(
                max_rate=self.current_rate_limit, 
                time_period=60
            )
            self.logger.info(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’èª¿æ•´: {self.current_rate_limit}/åˆ†")
            
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
    async def test_connection_fast(self) -> bool:
        """OpenAI APIã¸ã®è»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ç”¨ï¼‰"""
        if not self.api_key:
            self.logger.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
            
        try:
            self.logger.debug("OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
            
            # çŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã§è»½é‡ãªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
            fast_timeout = aiohttp.ClientTimeout(total=5)  # 5ç§’ã«çŸ­ç¸®
            
            async with aiohttp.ClientSession(timeout=fast_timeout) as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                # æœ€å°é™ã®ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼ˆGPT-5ã®åˆ¶é™ã«å¯¾å¿œï¼‰
                test_data = {
                    "model": "gpt-5",
                    "messages": [{"role": "user", "content": "Hi"}],
                    "max_completion_tokens": 10  # GPT-5ã§ã¯max_completion_tokensã‚’ä½¿ç”¨
                }
                
                self.logger.debug(f"è»½é‡ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­: {self.base_url}/chat/completions")
                
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=test_data
                ) as response:
                    
                    if response.status == 200:
                        self.logger.info("OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                        return True
                    else:
                        error_text = await response.text()
                        self.logger.error(f"OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•— - HTTP {response.status}: {error_text}")
                        return False
                        
        except asyncio.TimeoutError:
            self.logger.error("OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return False
        except aiohttp.ClientError as e:
            self.logger.error(f"OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            self.logger.error(f"OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def test_connection(self) -> bool:
        """OpenAI APIã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆï¼ˆå¾“æ¥ç‰ˆã€è©³ç´°ãªãƒ†ã‚¹ãƒˆï¼‰"""
        if not self.api_key:
            self.logger.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
            
        try:
            self.logger.debug("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
            
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                test_data = {
                    "model": "gpt-5",
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_completion_tokens": 10  # GPT-5ã§ã¯max_completion_tokensã‚’ä½¿ç”¨
                }
                
                self.logger.debug(f"ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­: {self.base_url}/chat/completions")
                
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=test_data
                ) as response:
                    
                    if response.status == 200:
                        self.logger.info("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                        return True
                    else:
                        error_text = await response.text()
                        self.logger.error(f"OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•— - HTTP {response.status}: {error_text}")
                        return False
                        
        except asyncio.TimeoutError:
            self.logger.error("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return False
        except aiohttp.ClientError as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            return False
            
    def get_rate_limit_status(self) -> Dict:
        """ç¾åœ¨ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ³ã‚’å–å¾—"""
        return {
            "current_limit": self.current_rate_limit,
            "time_period": 60,
            "available": self.rate_limiter.max_rate - self.rate_limiter._rate_per_period
        }
        
    async def estimate_tokens(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # GPT-5ã®æ­£ç¢ºãªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãŒãªã„å ´åˆã®è¿‘ä¼¼è¨ˆç®—
        # æ—¥æœ¬èª: ç´„1æ–‡å­— = 1.5ãƒˆãƒ¼ã‚¯ãƒ³
        # è‹±èª: ç´„4æ–‡å­— = 1ãƒˆãƒ¼ã‚¯ãƒ³
        
        japanese_chars = sum(1 for c in text if ord(c) > 127)
        english_chars = len(text) - japanese_chars
        
        estimated_tokens = int(japanese_chars * 1.5 + english_chars * 0.25)
        return max(1, estimated_tokens)
    
    def _update_connection_status(self, success: bool, error_type: str = None, error: str = None):
        """æ¥ç¶šçŠ¶æ…‹ã‚’æ›´æ–°"""
        import time
        
        if success:
            self.connection_status = "healthy"
            self.last_successful_call = time.time()
            self.consecutive_failures = 0
            self.logger.debug("OpenAI APIæ¥ç¶šçŠ¶æ…‹: æ­£å¸¸")
        else:
            self.consecutive_failures += 1
            self.logger.warning(f"OpenAI APIæ¥ç¶šå¤±æ•—: {error_type} (é€£ç¶šå¤±æ•—: {self.consecutive_failures})")
            
            if self.consecutive_failures >= self.max_consecutive_failures:
                self.connection_status = "failed"
                self.logger.error(f"OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•— (é€£ç¶š{self.consecutive_failures}å›)")
            elif self.consecutive_failures >= 3:
                self.connection_status = "degraded"
                self.logger.warning(f"OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸å®‰å®š (é€£ç¶šå¤±æ•—: {self.consecutive_failures}å›)")
    
    async def _check_connection_health_fast(self) -> bool:
        """é«˜é€Ÿãªæ¥ç¶šçŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ï¼ˆåˆå›ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é€ä¿¡ã®é…å»¶ã‚’é˜²ãï¼‰"""
        if self.connection_status == "healthy":
            self.logger.debug("OpenAI APIæ¥ç¶šçŠ¶æ…‹: æ­£å¸¸ï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ï¼‰")
            return True
        
        if self.connection_status == "failed":
            # å¤±æ•—çŠ¶æ…‹ã®å ´åˆã¯å³åº§ã«Falseã‚’è¿”ã™ï¼ˆè‡ªå‹•å¾©å…ƒã¯è¡Œã‚ãªã„ï¼‰
            self.logger.warning("OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•—ï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ï¼‰")
            return False
        
        # ä¸å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯çŸ­æ™‚é–“å¾…æ©Ÿ
        if self.connection_status == "degraded":
            self.logger.warning("OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸å®‰å®šï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ï¼‰")
            await asyncio.sleep(1)  # 5ç§’ã‹ã‚‰1ç§’ã«çŸ­ç¸®
            return True
        
        # ä¸æ˜ãªçŠ¶æ…‹ã®å ´åˆã¯è»½é‡ãªæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
        if self.connection_status == "unknown":
            self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸æ˜ - è»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ï¼‰")
            return await self._attempt_recovery_fast()
        
        return False

    async def _check_connection_health(self) -> bool:
        """æ¥ç¶šçŠ¶æ…‹ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆå¾“æ¥ç‰ˆã€è©³ç´°ãªå¾©å…ƒå‡¦ç†ï¼‰"""
        if self.connection_status == "healthy":
            self.logger.debug("OpenAI APIæ¥ç¶šçŠ¶æ…‹: æ­£å¸¸")
            return True
        
        if self.connection_status == "failed":
            # å¤±æ•—çŠ¶æ…‹ã®å ´åˆã€è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œ
            if self.auto_recovery_enabled:
                self.logger.warning("OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•— - è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œä¸­...")
                if await self._attempt_recovery():
                    self.logger.info("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«æˆåŠŸã—ã¾ã—ãŸ")
                    return True
                else:
                    self.logger.error("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                self.logger.error("OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•— - è‡ªå‹•å¾©å…ƒãŒç„¡åŠ¹ã§ã™")
            return False
        
        # ä¸å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ã€çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œ
        if self.connection_status == "degraded":
            self.logger.warning("OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸å®‰å®š - çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™")
            await asyncio.sleep(5)
            return True
        
        # ä¸æ˜ãªçŠ¶æ…‹ã®å ´åˆ
        if self.connection_status == "unknown":
            self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸æ˜ - åˆå›æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™")
            if await self._attempt_recovery():
                return True
        
        return False
    
    async def _attempt_recovery_fast(self) -> bool:
        """è»½é‡ãªæ¥ç¶šå¾©å…ƒã‚’è©¦è¡Œï¼ˆé«˜é€Ÿãƒã‚§ãƒƒã‚¯ç”¨ï¼‰"""
        try:
            self.logger.info("OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
            
            # è»½é‡ãªæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆçŸ­ã„ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼‰
            if await self.test_connection_fast():
                self.connection_status = "healthy"
                self.consecutive_failures = 0
                self.logger.info("OpenAI APIæ¥ç¶šã®è»½é‡å¾©å…ƒã«æˆåŠŸã—ã¾ã—ãŸ")
                return True
            else:
                self.logger.warning("OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except asyncio.TimeoutError:
            self.logger.error("OpenAI APIè»½é‡æ¥ç¶šãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return False
        except Exception as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šã®è»½é‡å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    async def _attempt_recovery(self) -> bool:
        """æ¥ç¶šã®è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œï¼ˆå¾“æ¥ç‰ˆã€è©³ç´°ãªå¾©å…ƒå‡¦ç†ï¼‰"""
        try:
            self.logger.info("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
            if await self.test_connection():
                self.connection_status = "healthy"
                self.consecutive_failures = 0
                self.logger.info("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«æˆåŠŸã—ã¾ã—ãŸ")
                return True
            else:
                self.logger.warning("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except asyncio.TimeoutError:
            self.logger.error("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return False
        except Exception as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            return False
    
    def get_connection_status(self) -> Dict:
        """ç¾åœ¨ã®æ¥ç¶šçŠ¶æ…‹ã‚’å–å¾—"""
        import time
        
        status_info = {
            "status": self.connection_status,
            "consecutive_failures": self.consecutive_failures,
            "auto_recovery_enabled": self.auto_recovery_enabled
        }
        
        if self.last_successful_call:
            status_info["last_successful_call"] = time.strftime(
                "%Y-%m-%d %H:%M:%S", 
                time.localtime(self.last_successful_call)
            )
        
        return status_info
    
    async def process_image_attachments(self, message_attachments: List) -> List[Dict]:
        """Discordãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†ï¼ˆä¸¦åˆ—å‡¦ç†å¯¾å¿œï¼‰"""
        if not message_attachments:
            self.logger.info("ğŸ“ ç”»åƒæ·»ä»˜ãªã—")
            return []
        
        self.logger.info(f"ğŸ” ç”»åƒæ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {len(message_attachments)}å€‹ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«")
        
        # ç”»åƒãƒ‡ãƒ¼ã‚¿ã®åé›†ç”¨ãƒªã‚¹ãƒˆ
        image_data = []
        
        # ä¸¦åˆ—å‡¦ç†ã§ç”»åƒã‚’å‡¦ç†
        async def process_single_image(attachment):
            self.logger.debug(f"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ä¸­: {attachment.filename}")
            
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
            if self._is_image_file(attachment.filename):
                # ç”»åƒã®è©³ç´°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´å¯èƒ½ï¼‰
                detail = "auto"  # "low", "high", "auto"
                
                image_info = {
                    "url": attachment.url,
                    "detail": detail,
                    "filename": attachment.filename,
                    "size": attachment.size,
                    "content_type": getattr(attachment, 'content_type', 'unknown')
                }
                
                self.logger.debug(f"âœ… ç”»åƒã¨ã—ã¦èªè­˜: {attachment.filename}")
                return image_info
            else:
                self.logger.debug(f"âŒ ç”»åƒã¨ã—ã¦èªè­˜ã•ã‚Œãš: {attachment.filename}")
                return None
        
        # ä¸¦åˆ—å‡¦ç†ã§ç”»åƒã‚’å‡¦ç†
        import asyncio
        try:
            # éåŒæœŸå‡¦ç†ã¨ã—ã¦ä¸¦åˆ—å®Ÿè¡Œ
            tasks = [process_single_image(att) for att in message_attachments]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # æˆåŠŸã—ãŸçµæœã®ã¿ã‚’åé›†
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    self.logger.error(f"ç”»åƒ {i+1} ã®å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {result}")
                elif result:
                    image_data.append(result)
                    self.logger.info(f"âœ… ç”»åƒã¨ã—ã¦èªè­˜: {result['filename']}")
                    self.logger.info(f"  - URL: {result['url']}")
                    self.logger.info(f"  - ã‚µã‚¤ã‚º: {result['size']} bytes")
                    self.logger.info(f"  - è©³ç´°ãƒ¬ãƒ™ãƒ«: {result['detail']}")
                else:
                    self.logger.info(f"âŒ ç”»åƒã¨ã—ã¦èªè­˜ã•ã‚Œãš: {message_attachments[i].filename}")
                    
        except Exception as e:
            self.logger.error(f"ä¸¦åˆ—ç”»åƒå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å¾“æ¥ã®é€æ¬¡å‡¦ç†
            self.logger.info("ğŸ”„ ä¸¦åˆ—å‡¦ç†ã«å¤±æ•—ã€å¾“æ¥ã®é€æ¬¡å‡¦ç†ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            for i, attachment in enumerate(message_attachments):
                self.logger.info(f"æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ« {i+1} ã‚’å‡¦ç†ä¸­: {attachment.filename}")
                
                if self._is_image_file(attachment.filename):
                    detail = "auto"
                    image_info = {
                        "url": attachment.url,
                        "detail": detail,
                        "filename": attachment.filename,
                        "size": attachment.size,
                        "content_type": getattr(attachment, 'content_type', 'unknown')
                    }
                    image_data.append(image_info)
                    self.logger.info(f"âœ… ç”»åƒã¨ã—ã¦èªè­˜: {attachment.filename}")
                else:
                    self.logger.info(f"âŒ ç”»åƒã¨ã—ã¦èªè­˜ã•ã‚Œãš: {attachment.filename}")
        
        self.logger.info(f"ğŸ“Š ç”»åƒå‡¦ç†çµæœ: {len(image_data)}å€‹ã®ç”»åƒã‚’èªè­˜")
        return image_data
    
    def _is_image_file(self, filename: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        if not filename:
            self.logger.debug("ãƒ•ã‚¡ã‚¤ãƒ«åãŒç©ºã®ãŸã‚ã€ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èªè­˜ã—ã¾ã›ã‚“")
            return False
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp', '.tiff', '.tga'}
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã¦æ‹¡å¼µå­ã‚’ãƒã‚§ãƒƒã‚¯
        file_lower = filename.lower()
        is_image = any(file_lower.endswith(ext) for ext in image_extensions)
        
        # è©³ç´°ãƒ­ã‚°å‡ºåŠ›
        if is_image:
            self.logger.debug(f"âœ… ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èªè­˜: {filename} (æ‹¡å¼µå­: {[ext for ext in image_extensions if file_lower.endswith(ext)]})")
        else:
            self.logger.debug(f"âŒ ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦èªè­˜ã•ã‚Œãš: {filename}")
            self.logger.debug(f"  - æ¤œå‡ºã•ã‚ŒãŸæ‹¡å¼µå­: {[ext for ext in image_extensions if file_lower.endswith(ext)]}")
            self.logger.debug(f"  - ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ã‚‹æ‹¡å¼µå­: {sorted(image_extensions)}")
        
        return is_image
    

    
    async def start_health_monitoring(self):
        """æ¥ç¶šçŠ¶æ…‹ã®ç¶™ç¶šç›£è¦–ã‚’é–‹å§‹"""
        if not self.auto_recovery_enabled:
            return
        
        self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹ã®ç¶™ç¶šç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        while True:
            try:
                await asyncio.sleep(self.health_check_interval)
                
                # æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
                if self.connection_status in ["degraded", "failed"]:
                    self.logger.info("æ¥ç¶šçŠ¶æ…‹ãŒä¸å®‰å®šã§ã™ã€‚è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œä¸­...")
                    await self._attempt_recovery()
                    
            except asyncio.CancelledError:
                self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")
                break
            except Exception as e:
                self.logger.error(f"æ¥ç¶šçŠ¶æ…‹ç›£è¦–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(10)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯10ç§’å¾…æ©Ÿ
