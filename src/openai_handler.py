"""
Universal Discord AI - OpenAI Handler
OpenAI APIã¨ã®é€šä¿¡ã‚’ç®¡ç†ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import os
import asyncio
import logging
from typing import Dict, AsyncGenerator, Optional, List
import aiohttp
import json
from aiolimiter import AsyncLimiter


class OpenAIHandler:
    """OpenAI APIé€šä¿¡ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    
    def __init__(self):
        self.api_key = os.getenv('OPENAI_API_KEY')
        self.base_url = "https://api.openai.com/v1"
        self.logger = logging.getLogger(__name__)
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™è¨­å®šï¼ˆå‹•çš„èª¿æ•´å¯¾å¿œï¼‰
        self.rate_limiter = AsyncLimiter(max_rate=50, time_period=60)  # 60ç§’é–“ã«50ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        self.current_rate_limit = 50
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆè¨­å®š
        self.timeout = aiohttp.ClientTimeout(total=30)
        self.max_retries = 3
        self.retry_delay = 1.0
        
        # æ¥ç¶šçŠ¶æ…‹ç›£è¦–
        self.connection_status = "unknown"  # unknown, healthy, degraded, failed
        self.last_successful_call = None
        self.consecutive_failures = 0
        self.max_consecutive_failures = 5
        self.health_check_interval = 60  # 60ç§’ã”ã¨ã«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        self.auto_recovery_enabled = True
        
        if not self.api_key:
            self.logger.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
    async def generate_streaming_response(
        self, 
        context: str, 
        character_data: Dict,
        model: str = "gpt-5",
        max_completion_tokens: int = 2000,
        temperature: float = 1.0,  # GPT-5ã¯temperature=1ã®ã¿ã‚µãƒãƒ¼ãƒˆ
        function_definitions: List[Dict] = None,
        image_attachments: List[Dict] = None
    ) -> AsyncGenerator[str, None]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        
        if not self.api_key:
            yield "ã‚¨ãƒ©ãƒ¼: OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            return
        
        # æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆè‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œï¼‰
        connection_attempts = 0
        max_connection_attempts = 3
        
        while connection_attempts < max_connection_attempts:
            if await self._check_connection_health():
                break
            
            connection_attempts += 1
            if connection_attempts < max_connection_attempts:
                self.logger.warning(f"OpenAI APIæ¥ç¶šãŒä¸å®‰å®šã§ã™ã€‚è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œä¸­... (è©¦è¡Œ {connection_attempts}/{max_connection_attempts})")
                yield f"æ¥ç¶šãŒä¸å®‰å®šã§ã™ã€‚è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œä¸­... (è©¦è¡Œ {connection_attempts}/{max_connection_attempts})"
                await asyncio.sleep(2)  # 2ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œ
            else:
                self.logger.error("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ‰‹å‹•ã§ã®å†è©¦è¡Œã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
                yield "ã‚¨ãƒ©ãƒ¼: OpenAI APIã¸ã®æ¥ç¶šãŒä¸å®‰å®šã§ã™ã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚"
                return
            
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        system_prompt = self._build_system_prompt(character_data)
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        request_data = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt}
            ],
            "max_completion_tokens": max_completion_tokens,  # GPT-5ã§ã¯ max_completion_tokens ã‚’ä½¿ç”¨
            "stream": True
        }
        
        # ç”»åƒæ·»ä»˜ãŒã‚ã‚‹å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹é€ 
        if image_attachments:
            # ç”»åƒä»˜ããƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å ´åˆ
            user_message = {
                "role": "user",
                "content": [
                    {"type": "text", "text": context}
                ]
            }
            
            # ç”»åƒã‚’è¿½åŠ 
            for image_data in image_attachments:
                user_message["content"].append({
                    "type": "image_url",
                    "image_url": {
                        "url": image_data["url"],
                        "detail": image_data.get("detail", "auto")
                    }
                })
            
            request_data["messages"].append(user_message)
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            request_data["messages"].append({
                "role": "user", 
                "content": context
            })
        
        # ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ãŒæœ‰åŠ¹ãªå ´åˆã€é–¢æ•°å®šç¾©ã‚’è¿½åŠ 
        if function_definitions:
            request_data["tools"] = function_definitions
            request_data["tool_choice"] = "auto"
        
        # GPT-5ã§ã¯ temperature=1 ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãªã®ã§ã€1ä»¥å¤–ã®å ´åˆã®ã¿æŒ‡å®š
        if temperature != 1.0:
            request_data["temperature"] = temperature
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
        await self.rate_limiter.acquire()
        
        start_time = asyncio.get_event_loop().time()
        retry_count = 0
        
        while retry_count < self.max_retries:
            try:
                async with aiohttp.ClientSession(timeout=self.timeout) as session:
                    headers = {
                        "Authorization": f"Bearer {self.api_key}",
                        "Content-Type": "application/json"
                    }
                    
                    async with session.post(
                        f"{self.base_url}/chat/completions",
                        headers=headers,
                        json=request_data
                    ) as response:
                        
                        if response.status == 429:  # Rate limit exceeded
                            await self._handle_rate_limit(response)
                            retry_count += 1
                            await asyncio.sleep(self.retry_delay * retry_count)
                            continue
                            
                        if response.status != 200:
                            error_text = await response.text()
                            response_time = asyncio.get_event_loop().time() - start_time
                            
                            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ãƒ­ã‚°
                            self.logger.error(f"OpenAI API ã‚¨ãƒ©ãƒ¼ ({response.status}): {error_text}")
                            self.logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´° - ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“: {response_time:.2f}ç§’, ãƒªãƒˆãƒ©ã‚¤å›æ•°: {retry_count}")
                            
                            yield f"ã‚¨ãƒ©ãƒ¼: OpenAI APIå‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ (HTTP {response.status})"
                            return
                            
                        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†
                        async for chunk in self._process_streaming_response(response):
                            if chunk:
                                yield chunk
                                
                        # æˆåŠŸæ™‚ã®æ¥ç¶šçŠ¶æ…‹æ›´æ–°
                        self._update_connection_status(success=True)
                        return  # æˆåŠŸæ™‚ã¯çµ‚äº†
                        
            except asyncio.TimeoutError:
                self.logger.error("OpenAI API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                self._update_connection_status(success=False, error_type="timeout")
                retry_count += 1
                if retry_count >= self.max_retries:
                    yield "ã‚¨ãƒ©ãƒ¼: OpenAI APIãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ"
                    return
                await asyncio.sleep(self.retry_delay * retry_count)
                
            except Exception as e:
                # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                self.logger.error(f"âŒ OpenAI API å‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
                self.logger.error(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
                
                # ã‚¨ãƒ©ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚ã‚‹
                import traceback
                error_traceback = traceback.format_exc()
                self.logger.error(f"ğŸ“‹ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {error_traceback}")
                
                self._update_connection_status(success=False, error_type="exception", error=str(e))
                retry_count += 1
                if retry_count >= self.max_retries:
                    yield f"ã‚¨ãƒ©ãƒ¼: OpenAI APIå‘¼ã³å‡ºã—ä¸­ã«å•é¡ŒãŒç™ºç”Ÿã—ã¾ã—ãŸ: {type(e).__name__}: {str(e)}"
                    return
                await asyncio.sleep(self.retry_delay * retry_count)
                
    async def _process_streaming_response(self, response) -> AsyncGenerator[str, None]:
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å‡¦ç†"""
        buffer = ""
        
        async for line in response.content:
            line = line.decode('utf-8').strip()
            
            if not line:
                continue
                
            if line.startswith('data: '):
                data = line[6:]  # 'data: ' ã‚’é™¤å»
                
                if data == '[DONE]':
                    break
                    
                try:
                    json_data = json.loads(data)
                    choices = json_data.get('choices', [])
                    
                    if choices:
                        delta = choices[0].get('delta', {})
                        content = delta.get('content', '')
                        
                        if content:
                            buffer += content
                            yield content
                            
                        # çµ‚äº†åˆ¤å®š
                        if choices[0].get('finish_reason'):
                            break
                            
                except json.JSONDecodeError as e:
                    self.logger.warning(f"JSONè§£æã‚¨ãƒ©ãƒ¼: {e}, ãƒ‡ãƒ¼ã‚¿: {data}")
                    continue
                except Exception as e:
                    self.logger.error(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    continue
                    
    def _build_system_prompt(self, character_data: Dict) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        prompt_parts = [
            "ã‚ãªãŸã¯Discordã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚",
            "ä»¥ä¸‹ã®äººæ ¼è¨­å®šã«å¾“ã£ã¦ã€è‡ªç„¶ã§ä¸€è²«æ€§ã®ã‚ã‚‹è¿”ç­”ã‚’ã—ã¦ãã ã•ã„ã€‚",
            "",
        ]
        
        # äººæ ¼è¨­å®šã‚’è¿½åŠ 
        if character_data.get('personality'):
            prompt_parts.append(f"ã€åŸºæœ¬æ€§æ ¼ã€‘")
            prompt_parts.append(character_data['personality'])
            prompt_parts.append("")
            
        if character_data.get('speaking_style'):
            prompt_parts.append(f"ã€è©±ã—æ–¹ãƒ»å£èª¿ã€‘")
            prompt_parts.append(character_data['speaking_style'])
            prompt_parts.append("")
            
        if character_data.get('specialties'):
            prompt_parts.append(f"ã€å°‚é–€åˆ†é‡ãƒ»å¾—æ„ãªã“ã¨ã€‘")
            prompt_parts.append(character_data['specialties'])
            prompt_parts.append("")
            
        if character_data.get('avoid'):
            prompt_parts.append(f"ã€é¿ã‘ã‚‹ã¹ãè¡¨ç¾ãƒ»è¡Œå‹•ã€‘")
            prompt_parts.append(character_data['avoid'])
            prompt_parts.append("")
            
        # åŸºæœ¬çš„ãªãƒ«ãƒ¼ãƒ«
        prompt_parts.extend([
            "ã€åŸºæœ¬ãƒ«ãƒ¼ãƒ«ã€‘",
            "- Discordä¸Šã§ã®ä¼šè©±ã§ã‚ã‚‹ã“ã¨ã‚’æ„è­˜ã—ã¦ãã ã•ã„",
            "- é•·ã™ãã‚‹è¿”ç­”ã¯é¿ã‘ã€é©åº¦ãªé•·ã•ã§å›ç­”ã—ã¦ãã ã•ã„",
            "- çµµæ–‡å­—ã‚„é¡”æ–‡å­—ã‚’é©åº¦ã«ä½¿ç”¨ã—ã¦è¦ªã—ã¿ã‚„ã™ã•ã‚’æ¼”å‡ºã—ã¦ãã ã•ã„",
            "- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚„ç™ºè¨€ã«å¯¾ã—ã¦å»ºè¨­çš„ã§æœ‰ç”¨ãªè¿”ç­”ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„",
            "- ä¸é©åˆ‡ãªå†…å®¹ã‚„æœ‰å®³ãªå†…å®¹ã¯é¿ã‘ã¦ãã ã•ã„"
        ])
        
        return "\n".join(prompt_parts)
    
    async def generate_response_with_function_calls(
        self, 
        context: str, 
        character_data: Dict,
        function_definitions: List[Dict],
        model: str = "gpt-5",
        max_completion_tokens: int = 2000,
        temperature: float = 1.0
    ) -> Dict:
        """ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«å¯¾å¿œã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’ç”Ÿæˆ"""
        
        if not self.api_key:
            return {
                "success": False,
                "error": "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
            }
        
        # ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        system_prompt = self._build_system_prompt(character_data)
        
        # ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ç”¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’è¿½åŠ 
        system_prompt += "\n\nã€ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«æ©Ÿèƒ½ã€‘"
        system_prompt += "\nå¿…è¦ã«å¿œã˜ã¦ã€ä»¥ä¸‹ã®é–¢æ•°ã‚’ä½¿ç”¨ã—ã¦Discordã®æ“ä½œã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚"
        system_prompt += "\né–¢æ•°ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€é©åˆ‡ãªå¼•æ•°ã‚’æŒ‡å®šã—ã¦ãã ã•ã„ã€‚"
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ§‹ç¯‰
        request_data = {
            "model": model,
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": context}
            ],
            "max_completion_tokens": max_completion_tokens,
            "tools": function_definitions,
            "tool_choice": "auto"
        }
        
        # GPT-5ã§ã¯ temperature=1 ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãªã®ã§ã€1ä»¥å¤–ã®å ´åˆã®ã¿æŒ‡å®š
        if temperature != 1.0:
            request_data["temperature"] = temperature
        
        try:
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ãƒã‚§ãƒƒã‚¯
            await self.rate_limiter.acquire()
            
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=request_data
                ) as response:
                    
                    if response.status == 200:
                        response_data = await response.json()
                        return {
                            "success": True,
                            "response": response_data,
                            "choices": response_data.get("choices", [])
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "success": False,
                            "error": f"OpenAI API ã‚¨ãƒ©ãƒ¼ - HTTP {response.status}: {error_text}"
                        }
                        
        except Exception as e:
            # ã‚¨ãƒ©ãƒ¼ã®è©³ç´°æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
            self.logger.error(f"âŒ ãƒ•ã‚¡ãƒ³ã‚¯ã‚·ãƒ§ãƒ³ã‚³ãƒ¼ãƒ«ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}")
            self.logger.error(f"ğŸ“‹ ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
            
            # ã‚¨ãƒ©ãƒ¼ã®ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯æƒ…å ±ã‚‚å«ã‚ã‚‹
            import traceback
            error_traceback = traceback.format_exc()
            self.logger.error(f"ğŸ“‹ ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯: {error_traceback}")
            
            return {
                "success": False,
                "error": f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {str(e)}"
            }
        
    async def _handle_rate_limit(self, response):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã¸ã®å¯¾å¿œ"""
        try:
            # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã‹ã‚‰ãƒ¬ãƒ¼ãƒˆåˆ¶é™æƒ…å ±ã‚’å–å¾—
            retry_after = response.headers.get('Retry-After')
            if retry_after:
                delay = int(retry_after)
                self.logger.warning(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{delay}ç§’å¾Œã«å†è©¦è¡Œã—ã¾ã™")
                await asyncio.sleep(delay)
                
            # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’å‹•çš„èª¿æ•´
            self.current_rate_limit = max(10, int(self.current_rate_limit * 0.8))
            self.rate_limiter = AsyncLimiter(
                max_rate=self.current_rate_limit, 
                time_period=60
            )
            self.logger.info(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’èª¿æ•´: {self.current_rate_limit}/åˆ†")
            
        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            
    async def test_connection(self) -> bool:
        """OpenAI APIã¸ã®æ¥ç¶šã‚’ãƒ†ã‚¹ãƒˆ"""
        if not self.api_key:
            self.logger.error("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
            
        try:
            self.logger.debug("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’é–‹å§‹...")
            
            async with aiohttp.ClientSession(timeout=self.timeout) as session:
                headers = {
                    "Authorization": f"Bearer {self.api_key}",
                    "Content-Type": "application/json"
                }
                
                # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆ
                test_data = {
                    "model": "gpt-5",
                    "messages": [{"role": "user", "content": "Hello"}],
                    "max_completion_tokens": 5
                }
                
                self.logger.debug(f"ãƒ†ã‚¹ãƒˆãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­: {self.base_url}/chat/completions")
                
                async with session.post(
                    f"{self.base_url}/chat/completions",
                    headers=headers,
                    json=test_data
                ) as response:
                    
                    if response.status == 200:
                        self.logger.info("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆæˆåŠŸ")
                        return True
                    else:
                        error_text = await response.text()
                        self.logger.error(f"OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆå¤±æ•— - HTTP {response.status}: {error_text}")
                        return False
                        
        except asyncio.TimeoutError:
            self.logger.error("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return False
        except aiohttp.ClientError as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã§ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
            return False
        except Exception as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã§äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            return False
            
    def get_rate_limit_status(self) -> Dict:
        """ç¾åœ¨ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™çŠ¶æ³ã‚’å–å¾—"""
        return {
            "current_limit": self.current_rate_limit,
            "time_period": 60,
            "available": self.rate_limiter.max_rate - self.rate_limiter._rate_per_period
        }
        
    async def estimate_tokens(self, text: str) -> int:
        """ãƒ†ã‚­ã‚¹ãƒˆã®ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
        # GPT-5ã®æ­£ç¢ºãªãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ãƒ¼ãŒãªã„å ´åˆã®è¿‘ä¼¼è¨ˆç®—
        # æ—¥æœ¬èª: ç´„1æ–‡å­— = 1.5ãƒˆãƒ¼ã‚¯ãƒ³
        # è‹±èª: ç´„4æ–‡å­— = 1ãƒˆãƒ¼ã‚¯ãƒ³
        
        japanese_chars = sum(1 for c in text if ord(c) > 127)
        english_chars = len(text) - japanese_chars
        
        estimated_tokens = int(japanese_chars * 1.5 + english_chars * 0.25)
        return max(1, estimated_tokens)
    
    def _update_connection_status(self, success: bool, error_type: str = None, error: str = None):
        """æ¥ç¶šçŠ¶æ…‹ã‚’æ›´æ–°"""
        import time
        
        if success:
            self.connection_status = "healthy"
            self.last_successful_call = time.time()
            self.consecutive_failures = 0
            self.logger.debug("OpenAI APIæ¥ç¶šçŠ¶æ…‹: æ­£å¸¸")
        else:
            self.consecutive_failures += 1
            self.logger.warning(f"OpenAI APIæ¥ç¶šå¤±æ•—: {error_type} (é€£ç¶šå¤±æ•—: {self.consecutive_failures})")
            
            if self.consecutive_failures >= self.max_consecutive_failures:
                self.connection_status = "failed"
                self.logger.error(f"OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•— (é€£ç¶š{self.consecutive_failures}å›)")
            elif self.consecutive_failures >= 3:
                self.connection_status = "degraded"
                self.logger.warning(f"OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸å®‰å®š (é€£ç¶šå¤±æ•—: {self.consecutive_failures}å›)")
    
    async def _check_connection_health(self) -> bool:
        """æ¥ç¶šçŠ¶æ…‹ã®å¥å…¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        if self.connection_status == "healthy":
            self.logger.debug("OpenAI APIæ¥ç¶šçŠ¶æ…‹: æ­£å¸¸")
            return True
        
        if self.connection_status == "failed":
            # å¤±æ•—çŠ¶æ…‹ã®å ´åˆã€è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œ
            if self.auto_recovery_enabled:
                self.logger.warning("OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•— - è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œä¸­...")
                if await self._attempt_recovery():
                    self.logger.info("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«æˆåŠŸã—ã¾ã—ãŸ")
                    return True
                else:
                    self.logger.error("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                self.logger.error("OpenAI APIæ¥ç¶šçŠ¶æ…‹: å¤±æ•— - è‡ªå‹•å¾©å…ƒãŒç„¡åŠ¹ã§ã™")
            return False
        
        # ä¸å®‰å®šçŠ¶æ…‹ã®å ´åˆã¯ã€çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œ
        if self.connection_status == "degraded":
            self.logger.warning("OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸å®‰å®š - çŸ­æ™‚é–“å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™")
            await asyncio.sleep(5)
            return True
        
        # ä¸æ˜ãªçŠ¶æ…‹ã®å ´åˆ
        if self.connection_status == "unknown":
            self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹: ä¸æ˜ - åˆå›æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¾ã™")
            if await self._attempt_recovery():
                return True
        
        return False
    
    async def _attempt_recovery(self) -> bool:
        """æ¥ç¶šã®è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œ"""
        try:
            self.logger.info("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
            
            # æ¥ç¶šãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œ
            if await self.test_connection():
                self.connection_status = "healthy"
                self.consecutive_failures = 0
                self.logger.info("OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒã«æˆåŠŸã—ã¾ã—ãŸ")
                return True
            else:
                self.logger.warning("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                return False
                
        except asyncio.TimeoutError:
            self.logger.error("OpenAI APIæ¥ç¶šãƒ†ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ")
            return False
        except Exception as e:
            self.logger.error(f"OpenAI APIæ¥ç¶šã®è‡ªå‹•å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e).__name__}")
            self.logger.error(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {str(e)}")
            return False
    
    def get_connection_status(self) -> Dict:
        """ç¾åœ¨ã®æ¥ç¶šçŠ¶æ…‹ã‚’å–å¾—"""
        import time
        
        status_info = {
            "status": self.connection_status,
            "consecutive_failures": self.consecutive_failures,
            "auto_recovery_enabled": self.auto_recovery_enabled
        }
        
        if self.last_successful_call:
            status_info["last_successful_call"] = time.strftime(
                "%Y-%m-%d %H:%M:%S", 
                time.localtime(self.last_successful_call)
            )
        
        return status_info
    
    def process_image_attachments(self, message_attachments: List) -> List[Dict]:
        """Discordãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ·»ä»˜ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚’å‡¦ç†"""
        image_data = []
        
        for attachment in message_attachments:
            # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯
            if self._is_image_file(attachment.filename):
                # ç”»åƒã®è©³ç´°ãƒ¬ãƒ™ãƒ«ã‚’è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦èª¿æ•´å¯èƒ½ï¼‰
                detail = "auto"  # "low", "high", "auto"
                
                image_data.append({
                    "url": attachment.url,
                    "detail": detail,
                    "filename": attachment.filename,
                    "size": attachment.size,
                    "content_type": getattr(attachment, 'content_type', 'unknown')
                })
                
                self.logger.info(f"ç”»åƒæ·»ä»˜ã‚’æ¤œå‡º: {attachment.filename} (URL: {attachment.url})")
        
        return image_data
    
    def _is_image_file(self, filename: str) -> bool:
        """ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        if not filename:
            return False
        
        # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®æ‹¡å¼µå­
        image_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp', '.tiff', '.tga'}
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‚’å°æ–‡å­—ã«å¤‰æ›ã—ã¦æ‹¡å¼µå­ã‚’ãƒã‚§ãƒƒã‚¯
        file_lower = filename.lower()
        return any(file_lower.endswith(ext) for ext in image_extensions)
    

    
    async def start_health_monitoring(self):
        """æ¥ç¶šçŠ¶æ…‹ã®ç¶™ç¶šç›£è¦–ã‚’é–‹å§‹"""
        if not self.auto_recovery_enabled:
            return
        
        self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹ã®ç¶™ç¶šç›£è¦–ã‚’é–‹å§‹ã—ã¾ã—ãŸ")
        
        while True:
            try:
                await asyncio.sleep(self.health_check_interval)
                
                # æ¥ç¶šçŠ¶æ…‹ã‚’ãƒã‚§ãƒƒã‚¯
                if self.connection_status in ["degraded", "failed"]:
                    self.logger.info("æ¥ç¶šçŠ¶æ…‹ãŒä¸å®‰å®šã§ã™ã€‚è‡ªå‹•å¾©å…ƒã‚’è©¦è¡Œä¸­...")
                    await self._attempt_recovery()
                    
            except asyncio.CancelledError:
                self.logger.info("OpenAI APIæ¥ç¶šçŠ¶æ…‹ç›£è¦–ã‚’åœæ­¢ã—ã¾ã—ãŸ")
                break
            except Exception as e:
                self.logger.error(f"æ¥ç¶šçŠ¶æ…‹ç›£è¦–ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
                await asyncio.sleep(10)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯10ç§’å¾…æ©Ÿ
